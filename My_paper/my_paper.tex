% This is a sample document using the University of Minnesota, Morris, Computer Science
% Senior Seminar modification of the ACM sig-alternate style. Much of this content is taken
% directly from the ACM sample document illustrating the use of the sig-alternate class. Certain
% parts that we never use have been removed to simplify the example, and a few additional
% components have been added.

% See https://github.com/UMM-CSci/Senior_seminar_templates for more info and to make
% suggestions and corrections.

\documentclass{sig-alternate}
\usepackage{color}
\usepackage[colorinlistoftodos]{todonotes}

%%%%% Uncomment the following line and comment out the previous one
%%%%% to remove all comments
%%%%% NOTE: comments still occupy a line even if invisible;
%%%%% Don't write them as a separate paragraph
%\newcommand{\mycomment}[1]{}

\begin{document}

% --- Author Metadata here ---
%%% REMEMBER TO CHANGE THE SEMESTER AND YEAR AS NEEDED
\conferenceinfo{UMM CSci Senior Seminar Conference, April 2017}{Morris, MN}

\title{Automating Algorithm Design through Genetic Programming Hyper-Heuristics}

\numberofauthors{1}

\author{
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
\alignauthor
Elsa M. Browning\\
	\affaddr{Division of Science and Mathematics}\\
	\affaddr{University of Minnesota, Morris}\\
	\affaddr{Morris, Minnesota, USA 56267}\\
	\email{brow3924@morris.umn.edu}
}

\maketitle
\begin{abstract}
	Automating algorithm design is a current subject of research in several different fields. One field that has approached it is hyper-heuristic optimization. Hyper-heuristics are heuristic search methods which seek to automate the process of selecting, generating, or adapting several simpler heuristics in order to solve computational search problems. This process is usually done with machine learning techniques, but in this paper we will be focusing on an evolutionary computation technique called autoconstruction. This method loosely fits under the category of genetic programming which is a family of algorithms in EC designed for evolving programs.
	\todo[inline, color=yellow]{write better abstract...}
\end{abstract}

\keywords{Evolutionary Computation, Genetic Programming, Hyper-Heuristics, Autoconstruction}

\section{Introduction}
\label{sec:introduction}
\todo[inline, color=yellow]{Mostly notes right now}

Traditionally, genetic programming solutions to problems evolve, but almost everything else is specified by the system designer \cite{spector:2016}. In autoconstruction, the variation methods are evolving as well.
\todo[inline]{maybe put in abstract?}

In sections~\ref{sec:evocomp},~\ref{sec:GP},~and~\ref{sec:HH} we describe necessary background for understanding the rest of this paper. Next, we describe the history of automating algorithm design (AAD) with a focus on hyper-heuristics (HH) optimization in section~\ref{sec:history}. Then, in section~\ref{sec:gpvariants}, we go over a few different genetic programming variants used in HH and the success of two in particular. Finally, we will go over current research being done with stack-based genetic programming (one of the GP variants) in section~\ref{sec:ac}; the stack-based programming language called Push is used in this example along with a technique for AAD called autoconstruction.
\todo[inline, color=yellow]{this is long roadmap. Probably need to shorten}

\section{Background}
\label{sec:background}

\subsection{Evolutionary Computation}
\label{sec:evocomp}
Evolutionary Computation (EC) is a subfield of artificial intelligence that uses algorithms based on biological evolution to reach global optimization. This means algorithms, using techniques like mutation and sexual reproduction, try to find the best solution possible to a problem or class of problems. These algorithms start with a population of potential solutions and then the individuals (in the population) who perform the worst on given fitness tests are removed. The remaining individuals are mutated or recombined in some way to create a new population with the same number of individuals as the first population. Occasionally, depending on the techniques used, new individuals are introduced into the next population as well. This process is repeated until the \textit{global optima}, the best solution (or solutions) possible, is found. Sometimes an algorithm is not able to find a global optima due to the algorithm not being good enough, so all programs have a designated stopping point to prevent them from running forever. The stopping point can be things like a time limit or a limit on the number of generations that can be produced.
\todo[inline]{is there a way I can simplify this paragraph (particularly the first sentence) or reword it to be better...? Should I go into more technical details of EC?}

EC techniques are very useful and can solve a wide variety of problems. There are many different kinds of techniques, some of which are more suited to certain types of problems than others. Some examples include genetic algorithms, gene expression programming, and artificial immune systems to name a few. Genetic programming is the EC technique we will be focusing on in this paper.

\subsection{Genetic Programming}
\label{sec:GP}
Most EC methods produce solutions in the form of a single answer (or set of answers) to a problem. In genetic programming (GP), our solutions are in the form of programs. These programs then solve a problem (or class of problems), adding a level of abstraction to the problem solving process. 
\todo[inline]{I'm not actually sure abstraction is the right word here, but it sounds right... Also are the parenthesis above weird?}
This also automates a large part of the algorithm design process by allowing an algorithm to evolve rather than designing and revising the algorithm by hand.

GP works by encoding programs into a set of genes and then modifying those genes, usually with a genetic algorithm, to evolve a program which will perform well in a predefined task. The methods used to encode the programs into artificial chromosomes and to evaluate the fitness of a program are still under active research. There are several different GP representations and variations, each of which has pros and cons depending on the problem. We will go into more detail on these in section~\ref{sec:gpvariants}.

\subsection{Hyper-Heuristics}
\label{sec:HH}
\todo[inline, color=yellow]{def of HH, difference between meta-heuristics and HH (and why they are often confused), define ``heuristic" }

\subsection{History of AAD}
\label{sec:history}
Automating algorithm design (AAD) has been investigated by several different areas for at least 60 years. In the 1950s, the term ``machine learning" was defined as ``computers programming themselves"~\cite{pappa:2014}. This definition has changed over time to focus more on the learning aspect, but machine learning is still an important area in AAD. While out of the scope of our paper, machine learning plays a major role in the history of AAD and was one of the first fields to do so.

Focusing on the automation of heuristic methods, we can trace the beginnings of hyper-heuristics (HH) to the 1960s (however, the term HH was not coined until 2000)~\cite{pappa:2014}. Early approaches of HH focused on automatically setting the parameters of evolutionary algorithms~\cite{pappa:2014}. A \textit{parameter} used to be thought of as things like mutation rates and crossover, however the definition has expanded to include evolutionary algorithm components like selection mechanisms, and mutation and crossover operators~\cite{pappa:2014}. Many researchers still question which parameters to tune when designing HH systems. Traditionally, parameters are tuned before the evolution starts and controlled during the evolution~\cite{pappa:2014}. There are, however, exceptions.

The idea of \textit{self-adaption}, where an algorithm is able to tune itself to a given problem while solving it, emerged later.
\todo[inline]{add more about evolving evolution?}

Today there are two major types of HH: \textit{heuristic selection} and \textit{heuristic generation}; the first focuses on selecting the best algorithm from a set of existing heuristics while the latter focuses on generating a new heuristic from the components of existing heuristics~\cite{pappa:2014}. Heuristic generation uses several different methods for the generation process, but we will be focusing on heuristic generation techniques that use genetic programming.
\todo[inline, color=yellow]{I focus pretty heavily on HH, which is good because that is the focus of paper, but feels weird because it's less of `history of AAD' and more `history of HH'}

\section{Genetic Programming Variants}
\label{sec:gpvariants}
Hyper-heuristics (HH) use a two step process; the first step is to create a set of algorithmic primitives appropriate for tackling a specific problem class and the second step is searching that algorithmic primitive space~\cite{harris:2015}. We can use a variety of different techniques to search this space, one of which is genetic programming~(GP). In GP, there are many different variants to choose from, each of which has different strengths and weaknesses depending on the problem.

Harris et al.~\cite{harris:2015} investigates some of the different GP variants and compares the variants' results on the Boolean Satisfiability Problem (SAT). The SAT problem is defined as: given a Boolean formula, determine if there exists a set of values that can make the formula true~\cite{harris:2015}. For a simple example, if given $(x_{1} \wedge \neg x_{2})$ then, to solve the problem, $x_{1}$ would be labeled as $true$ and $x_{2}$ as $false$. This would evaluate to $(true \wedge \neg false)$ which would evaluate to $(true \wedge true)$ which would then evaluate to $true$. There are many instances of this problem, which makes it a good class of problems to use GP on. Harris et al.~\cite{harris:2015} chose to use a subproblem of SAT called 3-SAT, which constricts the form of the Boolean function to conjunctive normal form with clauses of three variables. This causes the form of functions to look like $(x_{1} \vee x_{2} \vee x_{3}) \wedge (x_{4} \vee x_{5} \vee x_{6}) \wedge ...$ where $x_{i}$'s can be reused or inverted~\cite{harris:2015}. The SAT problem is known for its complexity and NP-completeness, which is why Harris et al.~\cite{harris:2015} chose it. To be \textit{NP-complete} means that many other difficult problems can be reduced to this problem. 

The GP variants tested were Tree-based GP, Linear GP, Cartesian GP, Grammatical Evolution, and Stack-based GP. To determine any differences in performance, the five GP variants were implemented in a common framework which facilitated sharing as much code as possible~\cite{harris:2015}. This implementation may cause bias in the results, but this was a necessary risk because the alternative, attempting to maximize the performance of each GP variant at the cost of even implementation, would cause similar bias in the results~\cite{harris:2015}.
\todo[inline]{this whole paragraph (and the one below)is all same citation, how do I cite whole paragraph?}

The results from Harris et al.~\cite{harris:2015} show that the GP variant chosen has a significant impact on the success of the hyper-heuristic. Tree-based GP (TGP) and stack-based GP (SGP) performed the best and performed similarly to one another. Linear and Cartesian GP performed similarly to each other, but were not quite as good. Grammatical Evolution performed the worst. This does not mean that TGP and SGP are inherently better than other GP variants~--~it means that GP variants have different strengths and some are more suited to certain problem spaces than others.

However, because TGP and SGP are related and because SGP is used in AutoDoG (see section~\ref{sec:ac}),we have described some of the pros and cons of these GP variants in sections~\ref{sec:tgp}~and~\ref{sec:sgp}.

\todo[inline, color=yellow]{Reorganize and include results section under GP variants? include graph and/or table which show the significance of the results}

\subsection{Tree-based Genetic Programming}
\label{sec:tgp}

\subsection{Stack-based Genetic Programming}
\label{sec:sgp}

\section{Autoconstruction}
\label{sec:ac}
In genetic programming hyper-heuristics (GPHH), the goal is to use genetic programming to evolve a program that will solve hard computational search problems. The individual programs serve as potential solutions. In most GPHH, the potential solutions are evolving, but everything else is specified by the system designer. \todo[inline]{not sure how to phrase previous sentence. Also not sure if I need to clarify what I mean by ``potential solutions"} In autoconstruction (a form of GPHH), evolution is evolving as well. This happens by encoding the methods of variation into the programs that are evolving so that, as a program evolves, its variation methods also evolve (see section~\ref{sec:push} for how this works). A simplified definition of autoconstruction would be one or more parents producing one or more children, where the parents and children are programs which serve as potential solutions to a set of computational search problems.
\todo[inline, color=green]{TO NIC: is there more I could say to summarize autoconstruciton quickly or do you think this is fine? Should I say something about how autoconstruction = only genetic operator?}

Prior work on autoconstruction has explored a variety of system designs, but, until recently, none of them have been able to solve  problems. A new system called Autoconstructive Diversification of Genomes (AutoDoG) has broken this trend by solving at least one hard problem: Replace Space with Newline~\cite{spector:2016}. And, in recent unpublished work, AutoDoG has actually solved a problem called String Differences that has never been solved by other GP systems before~\cite{eva:2017}.
\todo[inline, color=yellow]{Not sure how much of this is introduction stuff}

\subsection{Push and Plush}
\label{sec:push}
Push is a stack-based programming language with a separate stack for each data type. It was developed for program evolution and autoconstruction was one of the driving forces behind the original design~\cite{spector:2016}. This is the programming language that AutoDoG, the system we describe in section~\ref{sec:autodog}, uses. Push programs are strings of instructions, constants, and parentheses with only one syntax requirement: the parentheses must be balanced~\cite{lee:2001}. Instructions are executed by putting them on the \texttt{exec} stack. If the necessary arguments are not available for the instruction to be executed, the instruction is skipped. For example, assume all stacks are empty and assume a program says \texttt{(1 2 integer\_add)}. This means push 1 and 2 onto the \texttt{integer} stack and push the \texttt{integer\_add} onto the \texttt{exec} stack~\cite{lee:tutorial}. The \texttt{integer\_add} instruction will try to execute: the first two integers (in this case 1 and 2)  are popped off the top of the \texttt{integer} stack, added together, and the result (in this case 3) is pushed back on to the \texttt{integer} stack. Since there were enough arguments, the instruction executes: 1 and 2 are popped off the \textit{integer} stack and 3 is pushed onto the \textit{integer} stack. If, instead, the program was \texttt{(1 integer\_add)} then it would push 1 onto the \texttt{integer} stack, but skip the \texttt{integer\_add} because there are not enough integers in the \texttt{integer} stack for the instruction to execute. This would leave us with 1 on the \textit{integer} stack.
\todo[inline]{not sure I should include example inline like this, might want to separate out to a figure and try to shorten somehow}

Plush is a linear genome format for Push~\cite{spector:2016}. This can be thought of as computerized DNA. It is a program in a linear format to make program evolution easier.
\todo[inline, color=green]{TO NIC: Is this accurate? This is how I have been thinking about linear genomes. Is this actually linear GP and using the registers (if so, should I talk about registers) or is it different?}
In section~\ref{sec:autodog}, AutoDoG is actually evolving linear genomes and then translating those genomes back into Push programs~\cite{spector:2016}. This allows for methods of variation in a population to be encoded and evolved more easily. To aid in the translation process, Plush uses ``epigenetic close markers" (in other words, parenthesis) to separate blocks of code~\cite{spector:2016}. It also uses ``epigenetic silencing markers" to indicate when a part of the code in a genome should not be translated into a Push program~\cite{spector:2016}. This is arguably quite similar to how DNA and evolution work in biology in that some people are carriers for specific traits, but do not show them. This allows for these traits to be passed on to the next generation.
\todo[inline, color=green]{TO NIC: I might want to talk about why this is useful... why is this useful?}

\subsection{AutoDoG}
\label{sec:autodog}
In this section, we briefly describe some of the key features of AutoDoG.

When designing AutoDoG, Spector et al.~\cite{spector:2016} wanted to maintain diversity in parent selection. To do this, AutoDoG uses Lexicase Selection, described below: 

In each parent selection event,
\begin{itemize}
	\item start with a pool of the entire population
	\item filter the pool based on how each program performs on individual fitness cases (performed in random order, and one at a time)
	\item In each fitness case, only retain programs that are best on that case.
\end{itemize}
\todo[inline]{List or paragraph?}
\todo[inline]{Add more/better description of lexi (reread section in helmuth's dissertation)}

Its name comes from the way it filters the population using a kind of ``lexigraphic ordering" of cases \cite{spector:2016}. When tested on a benchmark suite of problems taken from introductory programming textbooks and compared to the results of other current GP parent selection techniques, Lexicase Selection allows for the solution of more problems in fewer generations~\cite{spector:2016}.
\todo[inline]{rephrase prev sentence?}

Another thing that Spector et al.~\cite{spector:2016} was concerned about when designing AutoDoG was cloning. This happens when an exact copy of a program moves on to the next generation. This is concerning because it can cause early convergence~--~it is possible that a population could lose all diversity and this could prevent the system from reaching a solution.
\todo[inline, color=green]{TO NIC: is this (prev sentence) actually a concern? I assume it is, but maybe it's so unlikely that it's not}
Cloning also significantly slows down the rate of evolution. This is bad because we want to reach a solution quickly. Most autoconstruction systems have some form of the ``no cloning rule," and AutoDoG has a form of this as well~\cite{spector:2016}. AutoDoG's version of this requires offspring to pass a more stringent diversification test in order to enter the population~\cite{spector:2016}. This test starts by taking an individual genome for the next generation. Then, that individual takes itself as a mate and makes temporary children. If the children differ enough from the individual and from each other, the individual enters the population and the children are discarded. If the individual fails, a random genome is generated and the test is repeated on the random genome. If the random genome fails, a blank genome (with no code in it) is generated and passed on to the next generation.

AutoDoG works similarly to PushGP, a reasonably standard generational programming system, but is run with autoconstruction as the sole genetic operator rather than using human designed mutation and crossover operators. In PushGP, the rate of mutation and crossover and other things is set by the designers. In AutoDoG, methods for making children are created by the designers, but the rates at which these methods are used or how the methods get used changes through the evolution of the program. For example, \texttt{genome\_uniform\_addition} is an instruction which inserts random instructions into a program with a likelihood taken from the top of the \texttt{:float} stack.
\todo[inline]{say more about this}

\subsection{Results}
\label{sec:results}
AutoDoG is unique among autoconstructive systems in that it can solve hard problems. However, as stated by Spector et al.~\cite{spector:2016},
\begin{quotation}
	We do not know which of these, or which combinations of these, may be responsible for the fact that AutoDoG appears to be capable of solving more difficult problems than previous autoconstructive evolution systems.
\end{quotation}
This is because it's hard to separate the pieces; there are a lot of intertwined elements of AutoDoG and Push. Separating them to find exactly which elements contribute to the success without unraveling the entire system is difficult and has not yet been accomplished.
\todo[inline, color=green]{TO NIC: Is this (above) more correct?}

One challenging problem AutoDoG has solved is Replace Space with Newline (RSWN). This is a software synthesis problem that takes in a string and prints that string with all spaces replaced by newlines. It also must return the integer count of the non-whitespace characters. This is complex because it involves multiple data types, such as strings and integers, and multiple outputs.

AutoDoG does not actually do better than standard PushGP on this problem. It succeeds less reliably than PushGP. AutoDoG solves the RSWN problem 5--10\% of the time, producing general solutions~\cite{spector:2016}. This may not seem like much, but the fact that AutoDoG solves the problem at all is actually quite impressive. It is not surprising that AutoDoG performs less reliably because AutoDoG has to learn how to evolve as well as learn how to solve the problem. In recent unpublished work however, there may be examples of autoconstruction performing `better' than PushGP in a more meaningful sense; autoconstruction has found solutions to problems, such as String Differences, that have never been solved with regular PushGP (or any other GP system)~\cite{eva:2017}.

\todo[inline]{Add more info about new AutoDoG results}

One interesting thing to note about AutoDoG is how it evolves. In standard PushGP, one can see a steady incline in differences between the genomes of parents and their children. Over time, change occurs at a steady rate and is not very dramatic from one generation to the next. In AutoDoG, there are big differences between the genomes of some parents and their children. This is interesting because the methods for evolution are encoded into the genomes in AutoDoG. These DL graphs \todo[inline]{insert DL graphs or cut this paragraph} show us how evolution is affected from one generation to the next.
\todo[inline, color=yellow]{Clean up, more info about weird AutoDoG evolution.}
\section{Conclusions and Future Work}
\label{sec:conclusion}
Automating algorithm design (AAD) has been a subject of research for at least the past 60 years. Hyper-heuristic optimization is a field that has devoted a lot of attention to this subject. Hyper-heuristics (HH) are heuristics that seek to automate the process of selecting, generating, or adapting simpler heuristics in order to solve computational search problems. HH are made up of a two step process: designing an algorithmic primitive space and searching that space. There are several ways to search the primitive space, but genetic programming (GP) is a very successful family of algorithms often chosen for this task. However, as discussed in Harris et al.~\cite{harris:2015}, the GP variant used may affect the overall success of a hyper-heuristic. AutoDoG, a system that has recently seen a lot of success, uses a technique called autoconstruction to evolve programs and it does this on a SGP language called Push. This system, designed by Spector et al.~\cite{spector:2016} solves Replace Space with Newline 5--10\% of the time. This is a very promising for the world of AAD.

However, according to Pappa et al.~\cite{pappa:2014} in 2014, machine learning was ahead of hyper-heuristics optimization on the subject of AAD and ``can operate over different datasets, from different problem domains, and even with different features." This is not to say that hyper-heuristic optimization is no longer useful--HH can be used on different kinds of problems. It would be interesting to see machine learning techniques combined with HH and is something that may happen in future work.

Something else that would be interesting to see is how different GP variants effect AutoDoG's success.
\todo[inline]{more summarizing and discussion}

\section{Acknowledgments}
\label{sec:acknowledgments}


% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
% my_paper.bib is the name of the BibTex file containing the
% bibliography entries. Note that you *don't* include the .bib ending here.
\bibliography{my_paper}  
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references

\todo[inline, color=yellow]{Add last of references to bib}
\todo[inline, color=yellow]{note to self: all these notes take up about half a page!}

\end{document}


\subsection{My nifty subsection}
\label{sec:mysubsection}

I want to refer to Section~\ref{sec:evocomp}
and Figure~\ref{fig:twoColumnFigure}. It would also be nice
to cite~\cite{spector:2016} and~\cite{pappa:2014} and~\cite{eva:2017}.

Let's make an equation:
\[
\textrm{area} = \pi r^2
\]
I want to refer to Section~\ref{sec:typeChangesSpecialChars}
and Figure~\ref{fig:twoColumnFigure}. It would also be nice
to cite~\cite{spector:2016}.
We can also do inline equations: $s = \sum_{i=0}^N x_i$.
I want to refer to Section~\ref{sec:typeChangesSpecialChars}
and Figure~\ref{fig:twoColumnFigure}. It would also be nice
to cite~\cite{spector:2016}.\[
s = \sum_{i=0}^N x_i
\]

Typically, the body of a paper is organized
into a hierarchical structure, with numbered or unnumbered
headings for sections, subsections, sub-subsections, and even
smaller sections.  The command \texttt{\textbackslash section} that
precedes this paragraph is part of such a
hierarchy.\footnote{This is the second footnote.  It
	starts a series of three footnotes that add nothing
	informational, but just give an idea of how footnotes work
	and look. It is a wordy one, just so you see
	how a longish one plays out.} \LaTeX\ handles the numbering
and placement of these headings for you, when you use
the appropriate heading commands around the titles
of the headings.